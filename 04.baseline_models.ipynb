{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e982c3f2-46ab-419b-95b1-cc72f444dc7e",
   "metadata": {},
   "source": [
    "## Base models\n",
    "\n",
    "In this notebook we will use some regression models to our data WITHOUT any tuning and data preprocessing (except missing value filling, encoding and scaling). Results which we will receive will be our base results which we will try to upgrade in the next notebooks\n",
    "\n",
    "We will use 4 baseline models. DummyRegressor, Linear Regression (OLS), Ridge regression, and RandomForest regression. But it doesn't mean that we will not use some other models in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e305e580-475d-4124-aac9-c09c74cfe087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae39bd9-7721-4802-9deb-eacd5953444f",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f8b006-881e-4457-90c6-139bc46a652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train_without_nans.csv\")\n",
    "sub = pd.read_csv(\"data/test_without_nans.csv\")\n",
    "\n",
    "encoded_data = pd.read_csv(\"data/encoded_train.csv\")\n",
    "encoded_sub = pd.read_csv(\"data/encoded_test.csv\")\n",
    "\n",
    "scaled_data = pd.read_csv(\"data/scaled_train.csv\")\n",
    "scaled_sub = pd.read_csv(\"data/scaled_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060097b7-b214-4dff-8a68-5182d0e096b9",
   "metadata": {},
   "source": [
    "### Train/test split & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411a9b66-807f-4243-a757-7eb26c3be812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage' 'LotArea' 'OverallQual' 'OverallCond' 'YearBuilt'\n",
      " 'YearRemodAdd' 'MasVnrArea' 'BsmtFinSF1' 'BsmtFinSF2' 'BsmtUnfSF'\n",
      " 'TotalBsmtSF' '1stFlrSF' '2ndFlrSF' 'LowQualFinSF' 'GrLivArea'\n",
      " 'BsmtFullBath' 'BsmtHalfBath' 'FullBath' 'HalfBath' 'BedroomAbvGr'\n",
      " 'KitchenAbvGr' 'TotRmsAbvGrd' 'Fireplaces' 'GarageYrBlt' 'GarageCars'\n",
      " 'GarageArea' 'WoodDeckSF' 'OpenPorchSF' 'EnclosedPorch' '3SsnPorch'\n",
      " 'ScreenPorch' 'PoolArea' 'MiscVal' 'MoSold' 'YrSold']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1167, 312)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = encoded_data.drop([\"SalePrice\"], axis=1)\n",
    "y = encoded_data[\"SalePrice\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "continuous_columns = data.select_dtypes(exclude=\"object\").drop([\"SalePrice\", \"Id\", \"MSSubClass\"], axis=1).columns.values\n",
    "\n",
    "print(continuous_columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[continuous_columns] = scaler.fit_transform(X_train[continuous_columns])\n",
    "X_test[continuous_columns] = scaler.transform(X_test[continuous_columns])\n",
    "\n",
    "real_y_train = y_train.copy()\n",
    "real_y_test = y_test.copy()\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8569ebb-eac1-4b8d-a1f4-a1eef5dfcfa7",
   "metadata": {},
   "source": [
    "## DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b423784-9f5e-476f-84d4-9e1d27080bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN LOG RMSE: 0.39752651637288144\n",
      "TEST LOG RMSE: 0.4074188586002447\n",
      "........................................\n",
      "TRAIN RMSE 81724.9360837574\n",
      "TEST RMSE 75334.24405265198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_reg = DummyRegressor().fit(X_train, y_train)\n",
    "\n",
    "train_pred = dummy_reg.predict(X_train)\n",
    "test_pred = dummy_reg.predict(X_test)\n",
    "\n",
    "print(\"TRAIN LOG RMSE:\", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"TEST LOG RMSE:\", root_mean_squared_error(y_test, test_pred))\n",
    "print(\".\"*40)\n",
    "print(\"TRAIN RMSE\", root_mean_squared_error(real_y_train, np.exp(train_pred)))\n",
    "print(\"TEST RMSE\", root_mean_squared_error(real_y_test, np.exp(test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8540f4-e88c-4cb3-b6ad-c73a0926ab88",
   "metadata": {},
   "source": [
    "This will be our \"dummy\" baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218a37d-b801-4499-ba87-8cbda265f0ee",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa951910-d7a4-4d6c-97ab-703480e9b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN LOG RMSE: 0.08901084902093606\n",
      "TEST LOG RMSE: 1486858776.871644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "train_pred = lr_reg.predict(X_train)\n",
    "test_pred = lr_reg.predict(X_test)\n",
    "\n",
    "print(\"TRAIN LOG RMSE:\", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"TEST LOG RMSE:\", root_mean_squared_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073541d6-63ba-4e23-96c9-35d2c9f040f5",
   "metadata": {},
   "source": [
    "What we see? Abnormally large test error. Even when we used logarithmic scaling for the target which means our model must give us not large values. Let's check minimal and maximal predicted values for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef3a9ec-d6e6-410f-abd0-957bf95b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN TRAIN PREDICTION 10.640533447265625\n",
      "MIN TEST PREDICTION -22993138933.899933\n",
      "MAX TRAIN PREDICTION 13.55511474609375\n",
      "MAX TEST PREDICTION 7606283384.342773\n"
     ]
    }
   ],
   "source": [
    "print(\"MIN TRAIN PREDICTION\", np.min(train_pred))\n",
    "print(\"MIN TEST PREDICTION\", np.min(test_pred))\n",
    "print(\"MAX TRAIN PREDICTION\", np.max(train_pred))\n",
    "print(\"MAX TEST PREDICTION\", np.max(test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a15fc1-1c49-4ea3-b381-fed816b6a97b",
   "metadata": {},
   "source": [
    "Probably this is the problem of a strong overfitting. Let's check model's largest coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66446f2d-027a-4b25-8f4b-f29c039e754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrLivArea................  1.4165e+11\n",
      "BsmtFinSF1...............  1.3885e+11\n",
      "TotalBsmtSF.............. -1.3487e+11\n",
      "BsmtUnfSF................  1.3446e+11\n",
      "2ndFlrSF................. -1.1659e+11\n",
      "1stFlrSF................. -1.0700e+11\n",
      "GarageFinish_Unf......... -9.9042e+10\n",
      "GarageFinish_Fin......... -9.9042e+10\n",
      "GarageFinish_RFn......... -9.9042e+10\n",
      "BldgType_2fmCon..........  7.4781e+10\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_idx = np.argsort(-np.abs(lr_reg.coef_))\n",
    "coef = lr_reg.coef_[sorted_coef_idx]\n",
    "for i in range(0, 10):\n",
    "    print(\"{:.<025} {:< 010.4e}\".format(X_train.columns[sorted_coef_idx[i]], coef[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bcfe3-e4bf-4894-b96b-820a55c33831",
   "metadata": {},
   "source": [
    "We have very large coefficients near some features. This can be the problem of high correlation between some features.\n",
    "BUT we can handle this problem not only with deleting correlated features. Also we can use L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9a922-a138-4c2a-9124-992bc597a1bf",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1a0ff9-a485-4ee4-b65d-d424c8349d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN LOG RMSE: 0.09618528732536605\n",
      "TEST LOG RMSE: 0.12981291831482283\n",
      "...................................\n",
      "TRAIN RMSE 19857.26655927968\n",
      "TEST RMSE 21367.482670061567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge().fit(X_train, y_train)\n",
    "\n",
    "train_pred = ridge_reg.predict(X_train)\n",
    "test_pred = ridge_reg.predict(X_test)\n",
    "\n",
    "print(\"TRAIN LOG RMSE:\", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"TEST LOG RMSE:\", root_mean_squared_error(y_test, test_pred))\n",
    "print(\".\" * 35)\n",
    "print(\"TRAIN RMSE\", root_mean_squared_error(real_y_train, np.exp(train_pred)))\n",
    "print(\"TEST RMSE\", root_mean_squared_error(real_y_test, np.exp(test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0beb2d0-4fcf-47d8-b48e-14dc8058d4a0",
   "metadata": {},
   "source": [
    "## RandomForest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc229fb-fafa-4c0b-bdfe-cc893d9c348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN LOG RMSE: 0.055036627208820854\n",
      "TEST LOG RMSE: 0.13638607501637814\n",
      "...................................\n",
      "TRAIN RMSE 12283.778526735785\n",
      "TEST RMSE 22609.245556362668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "train_pred = rf_reg.predict(X_train)\n",
    "test_pred = rf_reg.predict(X_test)\n",
    "\n",
    "print(\"TRAIN LOG RMSE:\", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"TEST LOG RMSE:\", root_mean_squared_error(y_test, test_pred))\n",
    "print(\".\" * 35)\n",
    "print(\"TRAIN RMSE\", root_mean_squared_error(real_y_train, np.exp(train_pred)))\n",
    "print(\"TEST RMSE\", root_mean_squared_error(real_y_test, np.exp(test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e64e3-904a-41b0-88c3-ba35fce4b644",
   "metadata": {},
   "source": [
    "## Submission to kaggle\n",
    "\n",
    "Before submission we will use the whole train dataset for training. Because of the fact that ols gives us overflow we will submit onlu ridge and random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7e6c0f-b41b-4adc-bf96-26474b5e7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaled_data.drop([\"SalePrice\"], axis=1)\n",
    "scaled_y = scaled_data[\"SalePrice\"]\n",
    "\n",
    "ridge_reg = ridge_reg.fit(scaled_X, scaled_y)\n",
    "ridge_sub = pd.Series(np.exp(ridge_reg.predict(scaled_sub)))\n",
    "ridge_sub_df = pd.DataFrame()\n",
    "ridge_sub_df[\"Id\"] = sub[\"Id\"]\n",
    "ridge_sub_df[\"SalePrice\"] = ridge_sub\n",
    "\n",
    "ridge_sub_df.to_csv(\"submissions/baseline/linear_ridge.csv\", index=False)\n",
    "\n",
    "\n",
    "rf_reg = rf_reg.fit(scaled_X, scaled_y)\n",
    "rf_sub = pd.Series(np.exp(rf_reg.predict(scaled_sub)))\n",
    "rf_sub_df = pd.DataFrame()\n",
    "rf_sub_df[\"Id\"] = sub[\"Id\"]\n",
    "rf_sub_df[\"SalePrice\"] = rf_sub\n",
    "\n",
    "rf_sub_df.to_csv(\"submissions/baseline/random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493ae9a-760b-42c7-9942-9bcf351ac5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
