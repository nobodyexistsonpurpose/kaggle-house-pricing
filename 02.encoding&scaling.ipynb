{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12f70ae-af5c-445a-8aa2-6b37c3ceb1ba",
   "metadata": {},
   "source": [
    "## Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa71f9f3-477f-47c5-bf8b-d82ee49fb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b399b8c-21c2-4fcd-823d-423b21e40572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_without_nan = pd.read_csv(\"data/train_without_nans.csv\")\n",
    "test_without_nan = pd.read_csv(\"data/test_without_nans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1eec751-8736-4e36-a93a-57254a445d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(train_without_nan.shape)\n",
    "print(test_without_nan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffd892-efc8-4ace-b16d-5cdce3b2da9d",
   "metadata": {},
   "source": [
    "## Features' dtypes\n",
    "\n",
    "First of all we need to understand if features' dtypes really corresponds to real features' meaning and if there is no mistake in dtype for a particular feature.\n",
    "\n",
    "To ensure that all is OK we need to check data_description.txt file and ensure that dtypes really correspond to the features\n",
    "\n",
    "Now let's separate object features from numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da7ead9-55f4-492f-9bd1-fc63a91b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = train_without_nan.select_dtypes(include='object')\n",
    "continuous_columns = train_without_nan.select_dtypes(exclude=\"object\").drop([\"SalePrice\", \"Id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d408f2f4-dc2c-421d-9803-f193cb12d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')\n",
      "(1459, 43)\n"
     ]
    }
   ],
   "source": [
    "print(object_columns.columns)\n",
    "print(object_columns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f720234-525d-443d-b2b4-c4a81bb6baba",
   "metadata": {},
   "source": [
    "With all categorical features there are no problem. They are really categorical. The only interesting thing is with features which have some ordering meaning like PoolQC or GarageQual. These features can be encoded with LabelEncoder and not with One Hot Encoding. But as the first version of encoding we will encode almost all categorical features with one hot except the features which have obly two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c4ea3b-b219-4a99-b1fd-d7ff86b0742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(continuous_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6c153-b8db-4b93-a49c-6220a4e34720",
   "metadata": {},
   "source": [
    "With continuous features there are several features which are categorical but were encoded in the data like numbers and thus pandas think they are continuous. \n",
    "\n",
    "* **MsSubClass** &ndash; 100% categorical feature\n",
    "* **OverallQual** &ndash; Also a categorical feature BUT can be interpretet as already encoded feature using label encoding and thus we will not encode it\n",
    "* **OverallCond** &ndash; The same situation as with OverallQual\n",
    "\n",
    "So we need to add MsSubClass feature to our object columns and remove it from the continuous ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295825b1-5e31-4927-b435-7648f2be1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns[\"MSSubClass\"] = train_without_nan[\"MSSubClass\"]\n",
    "continuous_columns = continuous_columns.drop([\"MSSubClass\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1348a1-a048-453f-8aa7-6395be8439fd",
   "metadata": {},
   "source": [
    "## Category features encoding\n",
    "\n",
    "Let's check how many category features we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4629c1-e372-4ba8-94e3-901532c8e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
       "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
       "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
       "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
       "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "       'SaleType', 'SaleCondition', 'MSSubClass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20d6e4-e6ab-42b3-86bb-1d3da93ac20d",
   "metadata": {},
   "source": [
    "It can be that the train and test sets have not the same set of categories in the same column (for example the test set can have some categories which the train set doesn't have). On this purpose we will stack train and test sets vertically together, then encode them and then split them back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed725f6-748b-4acd-8198-f3b373f04e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_without_nan = pd.concat([train_without_nan.drop(\"SalePrice\", axis=1), test_without_nan], axis=0, ignore_index=True)\n",
    "whole_without_nan = whole_without_nan.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3dcc91-399b-40e8-98a8-7a36730171a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n",
      "[5, 2, 3, 4, 4, 2, 5, 3, 25, 9, 8, 5, 8, 6, 8, 15, 16, 4, 4, 5, 6, 5, 5, 4, 7, 7, 6, 5, 2, 5, 4, 7, 6, 7, 4, 6, 6, 3, 4, 5, 5, 9, 6, 16]\n"
     ]
    }
   ],
   "source": [
    "category_counts = [whole_without_nan[column].value_counts().shape[0] for column in object_columns.columns]\n",
    "print(sum(category_counts))\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ab9f7-7222-4218-b02b-4329c1724ec5",
   "metadata": {},
   "source": [
    "We see that if we use, for example, one hot encoding, we will have additional 281 columns in our data (minus 44 because we will delete previous columns of taken feature).\n",
    "\n",
    "Anyway we have no better choice than encode features which have many categories with one hot encoding. To make our dataset at least a little bit smaller we will use label encoding for features which have only 2 categories. \n",
    "\n",
    "There are one additional problem which can appear. If we look more precisely at our category count we can see that our last category feature has more classes in test set than in train set. That means that during the tranformation of this feature in the test set we will have an error. To handle it we will set *handle_unknown* parameter in OneHotEncoder as *ignore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a452cc-047b-43a5-b9f3-6d4870d64670",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = whole_without_nan.copy()\n",
    "\n",
    "for column in object_columns.columns:\n",
    "    category_cnt = encoded[column].value_counts().shape[0]\n",
    "    if category_cnt == 2:\n",
    "        encoder = LabelEncoder()\n",
    "    \n",
    "        encoded[column] = encoder.fit_transform(encoded[column])\n",
    "    else:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        \n",
    "        one_hot_encoded = encoder.fit_transform(encoded[[column]])\n",
    "        \n",
    "        \n",
    "        one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out([column]))\n",
    "        \n",
    "        encoded = pd.concat([encoded, one_hot_df], axis=1)\n",
    "        encoded = encoded.drop([column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595d7714-b8b5-4cfa-bbfc-4b262d6b874b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2918, 314)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b63cf79-dea3-4373-b21a-e9e9cf770d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encoded.iloc[:1459].copy()\n",
    "encoded_train[\"SalePrice\"] = train_without_nan[\"SalePrice\"]\n",
    "\n",
    "encoded_test = encoded.iloc[1459:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9faf2ccd-4fac-4882-aee2-906592f811d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 315)\n",
      "(1459, 314)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_train.shape)\n",
    "print(encoded_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c752b-40c3-4ffa-a29f-d0ac9d803e8d",
   "metadata": {},
   "source": [
    "## Casting continuous features\n",
    "\n",
    "To work with all features we need to convert them to float. Because of the fact that we have encoded all categorical features now we have all our features numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f623fcb1-2539-45a2-8560-a136ddedaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encoded_train.astype(\"float64\")\n",
    "encoded_test = encoded_test.astype(\"float64\")\n",
    "\n",
    "encoded_train = encoded_train.drop([\"Id\"], axis=1)\n",
    "encoded_test = encoded_test.drop([\"Id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e604ec20-c1aa-4d1d-b91e-f67fe581ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train.to_csv(\"data/encoded_train.csv\", index=False)\n",
    "encoded_test.to_csv(\"data/encoded_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1eb01a-2afd-44d9-94ae-796b751f324c",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "In addition in this notebook we will create files with already scaled continuous features. Just not to do that in future notebooks.\n",
    "\n",
    "We scale all of the continuous columns as well as we do logarithmic transformation to the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a720825-79f3-4aaa-80c9-16b3eed7fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = encoded_train.copy() \n",
    "scaled_test = encoded_test.copy()\n",
    "\n",
    "columns2scale = continuous_columns.columns\n",
    "\n",
    "for column in columns2scale:\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaled_train[column] = scaler.fit_transform(scaled_train[[column]])\n",
    "    scaled_test[column] = scaler.transform(scaled_test[[column]])\n",
    "\n",
    "scaled_train[\"SalePrice\"] = np.log(scaled_train[\"SalePrice\"])\n",
    "\n",
    "scaled_train.to_csv(\"data/scaled_train.csv\", index=False)\n",
    "scaled_test.to_csv(\"data/scaled_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52f940-7f2c-4f81-9508-9fd876caaa9b",
   "metadata": {},
   "source": [
    "When we train some models in future we will need to use just **encoded_train.csv** file and not **scaled_train.csv** because during the training we need to split our WHOLE train data into train/test, then scale firstly train and then scale test using scale parameters of train to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3c47b-1a05-4e20-b077-bc71a3c4332b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
